name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  lint-and-format:
    name: ğŸ§¹ Lint and Format
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pylint black isort flake8 mypy bandit safety

      - name: ğŸ¨ Check code formatting with Black
        run: black --check --diff src/ tests/

      - name: ğŸ“‹ Check import sorting with isort
        run: isort --check-only --diff src/ tests/

      - name: ğŸ” Lint with flake8
        run: flake8 src/ tests/ --max-line-length=88 --extend-ignore=E203,W503

      - name: ğŸ•µï¸ Lint with pylint
        run: pylint src/ --disable=C0114,C0115,C0116,R0903 --max-line-length=88

      - name: ğŸ”¤ Type check with mypy
        run: mypy src/ --ignore-missing-imports --no-strict-optional

  security-scan:
    name: ğŸ”’ Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install security tools
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety

      - name: ğŸ›¡ï¸ Run Bandit security scanner
        run: bandit -r src/ -f json -o bandit-report.json || true

      - name: ğŸ“Š Upload Bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-security-report
          path: bandit-report.json

      - name: ğŸ” Check dependencies for security vulnerabilities
        run: safety check --json --output safety-report.json || true

      - name: ğŸ“Š Upload Safety report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: safety-security-report
          path: safety-report.json

  test:
    name: ğŸ§ª Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-xdist coverage

      - name: ğŸ§ª Run tests with coverage
        run: |
          pytest tests/ -v --cov=src/task_management --cov-report=xml --cov-report=html --cov-report=term-missing

      - name: ğŸ“Š Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: true

      - name: ğŸ“Š Upload coverage report
        uses: actions/upload-artifact@v4
        if: matrix.python-version == '3.12'
        with:
          name: coverage-report
          path: htmlcov/

  validate-tasks:
    name: âœ… Validate Task System
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: âœ… Validate task system integrity
        run: |
          python -m src.task_management.cli validate

      - name: ğŸ“Š Generate task analytics report
        run: |
          python -m src.task_management.cli analytics --type overview --output ci-analytics.json

      - name: ğŸ“Š Upload analytics report
        uses: actions/upload-artifact@v4
        with:
          name: task-analytics
          path: ci-analytics.json

  performance-check:
    name: âš¡ Performance Check
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-benchmark

      - name: âš¡ Run performance benchmarks
        run: |
          # Run basic CLI commands and measure performance
          time python -m src.task_management.cli list >/dev/null
          time python -m src.task_management.cli analytics --type overview >/dev/null

      - name: ğŸ“Š Generate performance report
        run: |
          echo "Performance benchmarks completed" > performance-report.txt
          echo "CLI list command: $(time python -m src.task_management.cli list >/dev/null 2>&1)" >> performance-report.txt

      - name: ğŸ“Š Upload performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: performance-report.txt

  build-check:
    name: ğŸ—ï¸ Build Check
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install build tools
        run: |
          python -m pip install --upgrade pip
          pip install build wheel setuptools

      - name: ğŸ—ï¸ Build package
        run: |
          python -m build

      - name: ğŸ“Š Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: dist/

  integration-test:
    name: ğŸ”— Integration Tests
    runs-on: ubuntu-latest
    needs: [lint-and-format, test]
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸ”— Run CLI integration tests
        run: |
          # Test main CLI commands
          python -m src.task_management.cli --help
          python -m src.task_management.cli list
          python -m src.task_management.cli analytics --type overview
          python -m src.task_management.cli validate
          python -m src.task_management.cli templates

      - name: ğŸ”— Test task operations
        run: |
          # Create a test task
          python -m src.task_management.cli create --id "ci-test-task" --title "CI Test Task" --description "Test task for CI/CD" --agent "CODEFORGE" --priority "medium"
          
          # List tasks to verify creation
          python -m src.task_management.cli list --filter "id:ci-test-task"
          
          # Update task status
          python -m src.task_management.cli status ci-test-task in_progress
          
          # Complete the task
          python -m src.task_management.cli status ci-test-task complete
          
          # Verify final state
          python -m src.task_management.cli list --filter "id:ci-test-task"

  documentation-check:
    name: ğŸ“š Documentation Check
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ“š Check documentation files
        run: |
          # Verify key documentation exists
          test -f README.md
          test -f CLAUDE.md
          test -f docs/github-integration-spec.md
          
          # Check for basic documentation quality
          grep -q "Agent Task Management System" README.md
          grep -q "## Project Overview" CLAUDE.md

      - name: ğŸ“š Validate markdown files
        uses: github/super-linter@v4
        env:
          DEFAULT_BRANCH: main
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          VALIDATE_ALL_CODEBASE: false
          VALIDATE_MARKDOWN: true

  quality-gate:
    name: ğŸšª Quality Gate
    runs-on: ubuntu-latest
    needs: [lint-and-format, security-scan, test, validate-tasks, performance-check, build-check, integration-test, documentation-check]
    if: always()
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸšª Check quality gate status
        run: |
          echo "Quality Gate Results:"
          echo "âœ… Lint and Format: ${{ needs.lint-and-format.result }}"
          echo "ğŸ”’ Security Scan: ${{ needs.security-scan.result }}"
          echo "ğŸ§ª Test Suite: ${{ needs.test.result }}"
          echo "âœ… Task Validation: ${{ needs.validate-tasks.result }}"
          echo "âš¡ Performance Check: ${{ needs.performance-check.result }}"
          echo "ğŸ—ï¸ Build Check: ${{ needs.build-check.result }}"
          echo "ğŸ”— Integration Tests: ${{ needs.integration-test.result }}"
          echo "ğŸ“š Documentation: ${{ needs.documentation-check.result }}"
          
          if [[ "${{ needs.lint-and-format.result }}" != "success" || \
                "${{ needs.test.result }}" != "success" || \
                "${{ needs.validate-tasks.result }}" != "success" || \
                "${{ needs.build-check.result }}" != "success" || \
                "${{ needs.integration-test.result }}" != "success" ]]; then
            echo "âŒ Quality gate failed - critical checks did not pass"
            exit 1
          else
            echo "âœ… Quality gate passed - all critical checks successful"
          fi

      - name: ğŸ‰ Success notification
        if: success()
        run: |
          echo "ğŸ‰ All quality checks passed! Ready for deployment."